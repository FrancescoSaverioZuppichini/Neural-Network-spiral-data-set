\relax 
\abx@aux@sortscheme{nty}
\abx@aux@refcontext{nty/global/}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}The Perceptron}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Question 1}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Vectorized equations}{1}}
\newlabel{eq:vectorized_perceptron}{{1}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}Mean Squared Error}{2}}
\newlabel{eq: MSE_perceptron}{{2}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3}Derivate of the error with respect to the weights}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.4}Compute the new weight values after one step using a learning rate of 0.02}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.5}Gradient Descend}{2}}
\newlabel{eq: GD}{{4}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Implement the MSE and dMSE}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Implement the function forward and backward}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Implement the \emph  {run\_part1}}{3}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \emph  {run\_part1} plot\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:runPart1}{{1}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}A Neural Network}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1} Implement the activation functions}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Question 2}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Forward pass}{3}}
\newlabel{eq:forwardPass}{{5}{3}}
\newlabel{eq:forwardPassVectorized}{{6}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Delta rules}{4}}
\newlabel{eq: deltaRule_1}{{7}{4}}
\newlabel{eq:deltaRule_2}{{8}{4}}
\newlabel{eq:deltaRule}{{9}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Derivatives of the weights}{4}}
\newlabel{eq:derivativesWeigthDeltas}{{11}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Implement the functions forward and backward of the Neural Network class.}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Train Network}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1} Split the data into a train set and a test set}{4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Train set and Test set\relax }}{5}}
\newlabel{fig: train_test_set}{{2}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Initialise the weights randomly and find a good learning rate to train}{5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Learning rate convergences\relax }}{5}}
\newlabel{fig: learning_rate_convergence}{{3}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Plot the learning rate of at least 5 different learning rates on both sets}{5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces model boundary vs learning rates\relax }}{6}}
\newlabel{fig: learning_rate_boundary}{{4}{6}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces eta vs grads and costs\relax }}{7}}
\newlabel{fig: grad_vs_grads_costs}{{5}{7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}Plot the boundary of the model which converged the most on the training data}{7}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Boundary of the model with MSE less than 0.02\relax }}{7}}
\newlabel{fig: NN_MSE_002_boundary}{{6}{7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Explain if this is a good model for the data}{7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Further Improvements}{8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Generic Implementation}{8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Initial weight and bias}{8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Performance}{8}}
\abx@aux@cite{Ruder}
\abx@aux@segm{0}{0}{Ruder}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \relax }}{9}}
\newlabel{table: performance_NN_BNN}{{1}{9}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Momentum}{9}}
\newlabel{eq: momentum}{{12}{9}}
\abx@aux@cite{AdaGrad}
\abx@aux@segm{0}{0}{AdaGrad}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Gradient Discent vs Momentum\relax }}{10}}
\newlabel{fig:momentum}{{7}{10}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Adagrad}{10}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Gradient Discent vs Adagrad\relax }}{11}}
\newlabel{fig: adagrad}{{8}{11}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Network deep}{11}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Stochastic Gradient Descent}{11}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Dropout}{12}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.9}Results}{12}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Boundary of the model\relax }}{12}}
\newlabel{fig: results_boundary}{{9}{12}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces BetterNeuralNetwork vs Neural Network\relax }}{13}}
\newlabel{fig: bnnVsNn}{{10}{13}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.10}Save and Load}{14}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.11}Animation}{14}}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{AdaGrad}{nty/global/}
\abx@aux@defaultrefcontext{0}{Ruder}{nty/global/}
